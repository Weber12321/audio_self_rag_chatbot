import os
import streamlit as st
import google.generativeai as genai
import asyncio


api_key = os.getenv("GOOGLE_API_KEY", "")
# Configure Gemini API
if not api_key:
    st.error(
        "ğŸš¨ GOOGLE_API_KEY not found in st.secrets! Please add it to your .env file."
    )
    st.stop()

# Configure Gemini API
genai.configure(api_key=api_key)

# === page config ===
if "pdf_content" not in st.session_state:
    st.session_state.pdf_content = ""

if "time_up" not in st.session_state:
    st.session_state.time_up = False

if "messages" not in st.session_state:
    st.session_state.messages = []


async def countdown_timer(chat_total_time):
    """
    Display a countdown timer with a progress bar asynchronously

    Parameters:
    - chat_total_time: Time in minutes for the countdown
    """
    # Create a progress bar
    progress_bar = st.progress(0)

    # Create a container for the timer text
    timer_text = st.empty()

    # Convert minutes to seconds
    total_seconds = chat_total_time * 60

    # Calculate steps for smooth countdown
    steps = 100
    step_time = total_seconds / steps

    # Countdown loop
    for i in range(steps, 0, -1):
        # Update progress bar
        if st.session_state.time_up:
            break
        progress_bar.progress((steps - i) / steps)

        # Display remaining time in minutes and seconds format
        remaining_seconds = i * step_time
        mins = int(remaining_seconds // 60)
        secs = int(remaining_seconds % 60)
        timer_text.text(f"å€’æ•¸è¨ˆæ™‚: {mins}åˆ†{secs}ç§’")

        # Use asyncio.sleep instead of time.sleep
        await asyncio.sleep(step_time)

    # Complete the progress bar
    progress_bar.empty()
    timer_text.text("æ™‚é–“åˆ°ï¼")

    # Return or set a flag to indicate timer completion
    st.session_state.time_up = True
    return None


# Helper function to run async function in a new thread
def run_async_timer(total_time):
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        loop.run_until_complete(countdown_timer(total_time))
    finally:
        loop.close()


st.title("æ–‡ä»¶å°è©±æ©Ÿå™¨äºº")

# === file upload ===
upload_files = st.file_uploader(
    "è«‹ä¸Šå‚³æ–‡ä»¶å…§å®¹", type=["pdf"], accept_multiple_files=True
)

if upload_files:
    for uploaded_file in upload_files:
        # Display file name
        st.write(f"è™•ç†æ–‡ä»¶: {uploaded_file.name}")

        # # Read PDF content
        # pdf_reader = PyPDF2.PdfReader(io.BytesIO(uploaded_file.getvalue()))

        # # Extract text from each page
        # text_content = ""
        # for page_num in range(len(pdf_reader.pages)):
        #     page = pdf_reader.pages[page_num]
        #     text_content += page.extract_text()

        # st.session_state.pdf_content += text_content

        # # Show a sample of the extracted content
        # st.write("å·²æå–æ–‡ä»¶å…§å®¹ï¼š")
        # st.write(text_content[:300] + "..." if len(text_content) > 300 else text_content)

# === timer ===
chat_total_time = st.number_input(
    "è«‹è¼¸å…¥è¨ˆæ™‚å™¨ï¼ˆåˆ†é˜ï¼‰", min_value=1, max_value=30, value=5, step=1
)

# === chat ===
start_chat = st.button("é–‹å§‹å°è©±")
if start_chat:
    # Call the async countdown timer function using threading
    import threading

    timer_thread = threading.Thread(target=run_async_timer, args=(chat_total_time,))
    timer_thread.daemon = True
    timer_thread.start()

    # Chat Stage
    st.subheader("èˆ‡æ–‡ä»¶å°è©±")

    with st.sidebar:
        stop_chat = st.button("åœæ­¢å°è©±")
        if stop_chat:
            st.session_state.time_up = True
            st.session_state.messages = []
            st.success("å°è©±å·²åœæ­¢ã€‚")

    # Display chat messages from history
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Function to generate response using Gemini
    def generate_gemini_response(conversation):
        try:
            # Configure the model
            model = genai.GenerativeModel("gemini-2.0-flash")

            # Create context with PDF content
            # context = (
            #     f"ä»¥ä¸‹æ˜¯æ–‡ä»¶å…§å®¹ï¼Œè«‹åŸºæ–¼é€™äº›å…§å®¹å›ç­”ç”¨æˆ¶çš„å•é¡Œï¼š\n\n{pdf_content}\n\n"
            # )

            # Generate response
            response = model.generate_content(conversation)
            return response.text
        except Exception as e:
            return f"ç”Ÿæˆå›æ‡‰æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}"

    # Accept user input
    if not st.session_state.time_up:
        if prompt := st.chat_input("è¼¸å…¥æ‚¨çš„å•é¡Œ"):
            # Add user message to chat history
            st.session_state.messages.append({"role": "user", "content": prompt})

            # Display user message in chat message container
            with st.chat_message("user"):
                st.markdown(prompt)

            # Display assistant response in chat message container
            with st.chat_message("assistant"):
                with st.spinner("æ€è€ƒä¸­..."):
                    # Create conversation history for context
                    conversation_history = ""
                    for msg in st.session_state.messages[
                        -5:
                    ]:  # Use last 5 messages for context
                        role = "ç”¨æˆ¶" if msg["role"] == "user" else "åŠ©æ‰‹"
                        conversation_history += f"{role}: {msg['content']}\n"

                    response = generate_gemini_response(conversation_history)
                    st.markdown(response)

            # Add assistant response to chat history
            st.session_state.messages.append({"role": "assistant", "content": response})
    else:
        st.info("å°è©±æ™‚é–“å·²çµæŸï¼Œè«‹é»æ“Š'é–‹å§‹å°è©±'é‡æ–°é–‹å§‹ã€‚")
